{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "\n",
    "import directoryFunctions ####\n",
    "import pathlib\n",
    "import data\n",
    "import time ####\n",
    "\n",
    "from tensorflow.keras.optimizers  import Adam\n",
    "from tensorflow.keras.callbacks   import CSVLogger, EarlyStopping, ModelCheckpoint, TensorBoard ####\n",
    "from tensorflow.keras.losses      import CategoricalCrossentropy\n",
    "from tensorflow.keras.layers      import Dense, Dropout, LSTM\n",
    "from tensorflow.keras             import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequences(datasetType):\n",
    "    sequences = []\n",
    "    labels    = []\n",
    "    for dataRow in dataObj.data[:]:\n",
    "        if(datasetType == dataRow[0]):\n",
    "            sequencePath = pathlib.Path(r\"D:\\ActionRecognition\\Sequences\")/dataRow[0]/dataRow[1]/(dataRow[2] + \"_featureSequence.npy\")\n",
    "            sequence     = np.load(sequencePath)\n",
    "            sequences.append(sequence)\n",
    "            label = dataObj.getClassIndex(dataRow[1])\n",
    "            labels.append(label)\n",
    "    return np.array(sequences), np.array(labels, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(sequences, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTrainDataset(dataset, cache, shuffleBufferSize):\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            dataset = dataset.cache(cache)\n",
    "        else:\n",
    "            dataset = dataset.cache()\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size = shuffleBufferSize)\n",
    "    # Repeat forever\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(256, input_shape=(None, 2048)))\n",
    "    model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(numClasses, activation = 'softmax')) # change 3 to numClasses\n",
    "    \n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.0001),\n",
    "                  loss      = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "                  metrics   = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, epochs, trainDataset, validationDataset, steps_per_epoch, validation_steps, callbacks):\n",
    "    history = model.fit(trainDataset, \n",
    "                        epochs = epochs,\n",
    "                        validation_data  = validationDataset,\n",
    "                        steps_per_epoch  = steps_per_epoch,\n",
    "                        validation_steps = validation_steps,\n",
    "                        callbacks = callbacks)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataObj    = data.Data()\n",
    "numClasses = dataObj.numClasses\n",
    "AUTOTUNE   = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    epochs = 5 ####\n",
    "    \n",
    "    cacheFilePath = \"./trainRNNDatasetCache\"\n",
    "    rootPath      = pathlib.Path(r\"D:\\ActionRecognition\") ####\n",
    "    rnnCallbacksDirectory = rootPath/'Callbacks'/'RNN'/f'{numClasses}' ####\n",
    "    \n",
    "    trainSequences, trainLabels           = getSequences('Train')\n",
    "    validationSequences, validationLabels = getSequences('Validation')\n",
    "    \n",
    "    trainDataset      = getDataset(trainSequences, trainLabels)\n",
    "    validationDataset = getDataset(validationSequences, validationLabels)\n",
    "    \n",
    "    trainDataset      = prepareTrainDataset(trainDataset, cacheFilePath, 100)\n",
    "    validationDataset = validationDataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    trainSeqCount      = dataObj.getDatasetCount('Train')\n",
    "    validationSeqCount = dataObj.getDatasetCount('Validation')\n",
    "    \n",
    "    steps_per_epoch  = np.ceil(trainSeqCount/BATCH_SIZE)\n",
    "    validation_steps = np.ceil(validationSeqCount/BATCH_SIZE)\n",
    "    \n",
    "    modelCheckpointDirectory = rnnCallbacksDirectory/'ModelCheckpoint' ####\n",
    "    tensorboardDirectory     = rnnCallbacksDirectory/'Tensorboard' ####\n",
    "    csvLoggerDirectory       = rnnCallbacksDirectory/'CSVLogger' ####\n",
    "    \n",
    "    directoryFunctions.createDirectory(csvLoggerDirectory) ####\n",
    "    \n",
    "    modelCheckpoint = ModelCheckpoint(filepath       = str(modelCheckpointDirectory/'RNN_{epoch:03d}_{val_loss:.2f}'),\n",
    "                                      save_best_only = True) ####\n",
    "    tensorboard     = TensorBoard(log_dir = str(tensorboardDirectory/f'{int(time.time())}')) ####\n",
    "    csvLogger       = CSVLogger(str(csvLoggerDirectory/f'{int(time.time())}.log')) ####\n",
    "    earlyStopping   = EarlyStopping(monitor = 'val_loss', patience = 7) ####\n",
    "    callbacks       = [modelCheckpoint, tensorboard, csvLogger, earlyStopping] ####\n",
    "    \n",
    "    model = getModel()\n",
    "    trained_model, history = trainModel(model, epochs, \n",
    "                                        trainDataset, validationDataset, \n",
    "                                        steps_per_epoch, validation_steps, callbacks) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 8.0 steps, validate for 3.0 steps\n",
      "Epoch 1/5\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 3.2280 - accuracy: 0.4018WARNING:tensorflow:From C:\\Users\\saddi\\Anaconda3\\envs\\Action_Recognition\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: D:\\ActionRecognition\\Callbacks\\RNN\\3\\ModelCheckpoint\\RNN_001_3.74\\assets\n",
      "8/8 [==============================] - 20s 2s/step - loss: 3.1465 - accuracy: 0.4023 - val_loss: 3.7443 - val_accuracy: 0.2169\n",
      "Epoch 2/5\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 3.5034 - accuracy: 0.1607INFO:tensorflow:Assets written to: D:\\ActionRecognition\\Callbacks\\RNN\\3\\ModelCheckpoint\\RNN_002_3.74\\assets\n",
      "8/8 [==============================] - 15s 2s/step - loss: 3.1943 - accuracy: 0.1641 - val_loss: 3.7429 - val_accuracy: 0.2530\n",
      "Epoch 3/5\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 3.4433 - accuracy: 0.4330INFO:tensorflow:Assets written to: D:\\ActionRecognition\\Callbacks\\RNN\\3\\ModelCheckpoint\\RNN_003_3.74\\assets\n",
      "8/8 [==============================] - 14s 2s/step - loss: 3.1545 - accuracy: 0.4648 - val_loss: 3.7426 - val_accuracy: 0.6747\n",
      "Epoch 4/5\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 3.4284 - accuracy: 0.2902INFO:tensorflow:Assets written to: D:\\ActionRecognition\\Callbacks\\RNN\\3\\ModelCheckpoint\\RNN_004_3.74\\assets\n",
      "8/8 [==============================] - 15s 2s/step - loss: 3.2445 - accuracy: 0.2617 - val_loss: 3.7423 - val_accuracy: 0.3494\n",
      "Epoch 5/5\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 3.4136 - accuracy: 0.2098INFO:tensorflow:Assets written to: D:\\ActionRecognition\\Callbacks\\RNN\\3\\ModelCheckpoint\\RNN_005_3.74\\assets\n",
      "8/8 [==============================] - 15s 2s/step - loss: 3.2058 - accuracy: 0.2188 - val_loss: 3.7422 - val_accuracy: 0.3253\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

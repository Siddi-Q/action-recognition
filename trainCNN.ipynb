{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "\n",
    "import directoryFunctions\n",
    "import pathlib\n",
    "import data\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.applications        import InceptionV3\n",
    "from tensorflow.keras.optimizers          import Adam\n",
    "from tensorflow.keras.callbacks           import CSVLogger, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers              import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.losses              import CategoricalCrossentropy\n",
    "from tensorflow.keras.models              import load_model, Sequential ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrameCount(dataDirectory):\n",
    "    return len(list(dataDirectory.glob('*/*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataSet(dataDirectory):\n",
    "    imagePathsDataset = tf.data.Dataset.list_files(str(dataDirectory/'*/*'))\n",
    "    return imagePathsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabeledData(imagePath):\n",
    "    def getLabel(imagePath):\n",
    "        # convert the path to a list of path components\n",
    "        parts = tf.strings.split(imagePath, os.path.sep)\n",
    "        # The second to last is the class-directory\n",
    "        return parts[-2] == classNames\n",
    "    \n",
    "    def decodeImg(img):\n",
    "        # convert the compressed string to a 3D uint8 tensor\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        # resize the image to the desired size.\n",
    "        return tf.image.resize(img, [299, 299])\n",
    "    \n",
    "    label = getLabel(imagePath)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(imagePath)\n",
    "    img = decodeImg(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTrainDataset(dataset, cache, shuffleBufferSize):\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            dataset = dataset.cache(cache)\n",
    "        else:\n",
    "            dataset = dataset.cache()\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size = shuffleBufferSize)\n",
    "    # Repeat forever\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    base_model = InceptionV3(input_shape = (299, 299, 3),\n",
    "                             include_top = False,\n",
    "                             weights     = 'imagenet')\n",
    "    base_model.trainable = False\n",
    "    global_average_layer = GlobalAveragePooling2D()\n",
    "    prediction_layer     = Dense(numClasses, activation = 'softmax')\n",
    "    \n",
    "    model = Sequential([base_model, global_average_layer, prediction_layer])\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr = 0.0001),\n",
    "                  loss      = CategoricalCrossentropy(from_logits = True),\n",
    "                  metrics   = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fineTuneModel(model, fineTuneAt):\n",
    "    base_model = model.layers[0]\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    for layer in base_model.layers[:fineTuneAt]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(optimizer = Adam(lr = 0.00001),\n",
    "                  loss      = CategoricalCrossentropy(from_logits = True),\n",
    "                  metrics   = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, initial_epoch, epochs, trainDataset, validationDataset, steps_per_epoch, validation_steps, callbacks):\n",
    "    history = model.fit(trainDataset,\n",
    "                        initial_epoch    = initial_epoch, \n",
    "                        epochs           = epochs, \n",
    "                        validation_data  = validationDataset,\n",
    "                        steps_per_epoch  = steps_per_epoch,\n",
    "                        validation_steps = validation_steps,\n",
    "                        callbacks        = callbacks)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataObj    = data.Data()\n",
    "numClasses = dataObj.numClasses\n",
    "classNames = np.array(dataObj.classes)\n",
    "\n",
    "AUTOTUNE   = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    initial_epoch    = 0\n",
    "    epochs           = 1\n",
    "    fine_tune_epochs = 2\n",
    "    fineTuneAt       = 249\n",
    "    \n",
    "    cachePath     = pathlib.Path(r\"./Cache\")\n",
    "    cacheFilePath = cachePath/'trainCNNDatasetCache'\n",
    "    directoryFunctions.removeDirectory(cachePath) ####\n",
    "    directoryFunctions.createDirectory(cachePath)\n",
    "    \n",
    "    rootPath      = pathlib.Path(r\"D:\\ActionRecognition\")\n",
    "    framesPath    = rootPath/'Frames'\n",
    "    \n",
    "    trainDataDirectory       = framesPath/'Train'\n",
    "    validationdataDirectory  = framesPath/'Validation'\n",
    "    cnnCallbacksDirectory    = rootPath/'Callbacks'/'CNN'/f'{numClasses}'\n",
    "    \n",
    "    trainFrameCount      = getFrameCount(trainDataDirectory)\n",
    "    validationFrameCount = getFrameCount(validationdataDirectory)\n",
    "    \n",
    "    trainDataset      = getDataSet(trainDataDirectory)\n",
    "    validationDataset = getDataSet(validationdataDirectory)\n",
    "    trainDataset      = trainDataset.map(getLabeledData,      num_parallel_calls=AUTOTUNE)\n",
    "    validationDataset = validationDataset.map(getLabeledData, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    trainDataset      = prepareTrainDataset(trainDataset, str(cacheFilePath), trainFrameCount)\n",
    "    validationDataset = validationDataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    steps_per_epoch  = np.ceil(trainFrameCount/BATCH_SIZE)\n",
    "    validation_steps = np.ceil(validationFrameCount/BATCH_SIZE)\n",
    "    \n",
    "    modelCheckpointDirectory = cnnCallbacksDirectory/'ModelCheckpoint'\n",
    "    tensorboardDirectory     = cnnCallbacksDirectory/'Tensorboard'\n",
    "    csvLoggerDirectory       = cnnCallbacksDirectory/'CSVLogger'\n",
    "    \n",
    "    directoryFunctions.createDirectory(csvLoggerDirectory)\n",
    "    directoryFunctions.createDirectory(modelCheckpointDirectory) ####\n",
    "    \n",
    "    modelCheckpoint = ModelCheckpoint(filepath       = str(modelCheckpointDirectory/(f'{int(time.time())}' + '_CNN_{epoch:03d}_{val_loss:.2f}.h5')),\n",
    "                                      save_best_only = True) #### add .h5 and added timeinfornt of it\n",
    "    tensorboard     = TensorBoard(log_dir = str(tensorboardDirectory/f'{int(time.time())}'))\n",
    "    csvLogger       = CSVLogger(str(csvLoggerDirectory/f'{int(time.time())}.log'))\n",
    "    earlyStopping   = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "    callbacks       = [modelCheckpoint, tensorboard, csvLogger, earlyStopping]\n",
    "    \n",
    "    ####---------------\n",
    "    savedModelPath = \"\" # insert path to saved model (.h5 file) here\n",
    "    if savedModelPath == \"\":\n",
    "        model                  = getModel()\n",
    "        trained_model, history = trainModel(model, initial_epoch, epochs, \n",
    "                                            trainDataset, validationDataset, \n",
    "                                            steps_per_epoch, validation_steps, [])\n",
    "        fine_tuned_model       = fineTuneModel(trained_model, fineTuneAt)\n",
    "        initial_epoch          = history.epoch[-1]\n",
    "    else:\n",
    "        fine_tuned_model = load_model(savedModelPath)\n",
    "        initial_epoch    = 0\n",
    "        fine_tune_epochs = 1\n",
    "    ####---------------\n",
    "    \n",
    "    trained_model, history_fine = trainModel(fine_tuned_model, \n",
    "                                             initial_epoch, fine_tune_epochs, \n",
    "                                             trainDataset, validationDataset,\n",
    "                                             steps_per_epoch, validation_steps,\n",
    "                                             callbacks) #### history.epoch[-1] -> initial_epoch\n",
    "    \n",
    "    directoryFunctions.removeDirectory(cachePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

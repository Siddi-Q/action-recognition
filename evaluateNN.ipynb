{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "\n",
    "import pathlib\n",
    "import config\n",
    "import data\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\"\"\"\n",
    "Documentation:\n",
    "- numpy\n",
    "    1. array()\n",
    "        - https://numpy.org/doc/stable/reference/generated/numpy.array.html?highlight=array#numpy.array\n",
    "    2. load()\n",
    "        - https://numpy.org/doc/stable/reference/generated/numpy.load.html?highlight=load#numpy.load\n",
    "    3. pad()\n",
    "        - https://numpy.org/doc/stable/reference/generated/numpy.pad.html?highlight=pad#numpy.pad\n",
    "- os\n",
    "    1. path.sep\n",
    "- pathlib\n",
    "    1. Path(), /, glob(), .name, .stem\n",
    "        - https://docs.python.org/3/library/pathlib.html\n",
    "- tensorflow\n",
    "    - data.Dataset\n",
    "        1. batch(), from_tensor_slices(), list_files(), map(), prefetch()\n",
    "            - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/data/Dataset\n",
    "    - keras\n",
    "        - applications.inception_v3\n",
    "            1. preprocess_input()\n",
    "                - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/applications/inception_v3\n",
    "        - models\n",
    "            1. load_model()\n",
    "                - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/models/load_model\n",
    "            2. Sequential()\n",
    "                1. predict(), evaluate()\n",
    "                    - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/Sequential\n",
    "        - preprocessing.image\n",
    "            1. img_to_array(), load_img()\n",
    "                - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/preprocessing/image\n",
    "    - image\n",
    "        1. convert_image_dtype(), decode_jpeg(), resize()\n",
    "            - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/image\n",
    "    -io\n",
    "        1. read_file()\n",
    "            - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/io/read_file\n",
    "    - strings\n",
    "        1. split()\n",
    "            - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/strings/split\n",
    "Sources:\n",
    "    1. Input pipeline using tf.data\n",
    "        - https://www.tensorflow.org/tutorials/load_data/images\n",
    "    2. Loading numpy arrays\n",
    "        - https://www.tensorflow.org/tutorials/load_data/numpy\n",
    "        - https://www.tensorflow.org/guide/data#consuming_numpy_arrays\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE   = tf.data.experimental.AUTOTUNE\n",
    "dataObj    = data.Data()\n",
    "numClasses = dataObj.numClasses\n",
    "classNames = np.array(dataObj.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Name: getBestSavedModel\n",
    "Number of parameters: 1\n",
    "List of parameters:\n",
    "    1. modelCheckpointPath | pathlib.Path | Path to the CNN model checkpoints.\n",
    "Pre-condition:\n",
    "    1. modelCheckpointPath exists.\n",
    "Post-condition:\n",
    "    1. Returns the path to the best model in the 'modelCheckpointPath' directory. The best model, is the one\n",
    "       that has the smallest loss.\n",
    "\"\"\"\n",
    "def getBestSavedModel(modelCheckpointPath):\n",
    "    dirPaths  = sorted(modelCheckpointPath.glob(\"*\"))\n",
    "    minLoss   = float('inf')\n",
    "    bestModel = \"\"\n",
    "    for dirPath in dirPaths:\n",
    "        modelname = pathlib.Path(dirPath.name).stem\n",
    "        loss = float(modelname.split(\"_\")[-1])\n",
    "        if loss <= minLoss:\n",
    "            bestModel = dirPath\n",
    "            minLoss   = loss\n",
    "    return str(bestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Name: evaluateCNN\n",
    "Number of parameters: 0\n",
    "List of parameters: n/a\n",
    "Pre-condition: n/a\n",
    "Post-condition:\n",
    "    1. Returns the results (evaluation) of a CNN model.\n",
    "\"\"\"\n",
    "def evaluateCNN():\n",
    "    def getDataSet(dataDirectory):\n",
    "        imagePathsDataset = tf.data.Dataset.list_files(str(dataDirectory/'*/*'))\n",
    "        return imagePathsDataset\n",
    "    \n",
    "    def getLabeledData(imagePath):\n",
    "        def getLabel(imagePath):\n",
    "            # convert the path to a list of path components\n",
    "            parts = tf.strings.split(imagePath, os.path.sep)\n",
    "            # The second to last is the class-directory\n",
    "            return parts[-2] == classNames\n",
    "    \n",
    "        def decodeImg(img):\n",
    "            # convert the compressed string to a 3D uint8 tensor\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "            # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "            img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "            # resize the image to the desired size.\n",
    "            return tf.image.resize(img, [299, 299])\n",
    "    \n",
    "        label = getLabel(imagePath)\n",
    "        # load the raw data from the file as a string\n",
    "        img = tf.io.read_file(imagePath)\n",
    "        img = decodeImg(img)\n",
    "        return img, label\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    cf         = config.Config()\n",
    "    rootPath   = pathlib.Path(cf.rootPath)\n",
    "    framesPath = pathlib.Path(cf.framesPath)\n",
    "    testDataDirectory   = framesPath/'Test'\n",
    "    modelCheckpointPath = rootPath/'Callbacks'/'CNN'/f'{numClasses}'/'ModelCheckpoint'\n",
    "\n",
    "    testDataset = getDataSet(testDataDirectory)\n",
    "    testDataset = testDataset.map(getLabeledData, num_parallel_calls = AUTOTUNE)\n",
    "    testDataset = testDataset.batch(BATCH_SIZE).prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "    savedModelPath = \"\" # you can insert the path to a saved model here\n",
    "    if savedModelPath == \"\":\n",
    "        savedModelPath = getBestSavedModel(modelCheckpointPath)\n",
    "    \n",
    "    savedModel = load_model(savedModelPath)\n",
    "    results = savedModel.evaluate(testDataset)\n",
    "    return results\n",
    "\n",
    "results = evaluateCNN()\n",
    "print(\"Loss: \", results[0], \"Accuracy: \", results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Name: evaluateRNN\n",
    "Number of parameters: 0\n",
    "List of parameters: n/a\n",
    "Pre-condition: n/a\n",
    "Post-condition:\n",
    "    1. Returns the results (evaluation) of a RNN model.\n",
    "\"\"\"\n",
    "def evaluateRNN():\n",
    "    def getDataset(sequences, labels):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
    "        return dataset\n",
    "    \n",
    "    def getSequences(datasetType):\n",
    "        maxFrameCount = dataObj.getMaxFrameCount()\n",
    "        sequences = []\n",
    "        labels    = []\n",
    "        sequencesPath = pathlib.Path(config.Config().sequencesPath)\n",
    "        for dataRow in dataObj.data[:]:\n",
    "            if(datasetType == dataRow[0]):\n",
    "                sequencePath = sequencesPath/dataRow[0]/dataRow[1]/(dataRow[2] + \"_featureSequence.npy\")\n",
    "                sequence     = np.load(sequencePath)\n",
    "                sequence     = np.pad(sequence, ((0, maxFrameCount - int(dataRow[3])), (0, 0)), 'edge')\n",
    "                sequences.append(sequence)\n",
    "                label = dataObj.getClassIndex(dataRow[1])\n",
    "                labels.append(label)\n",
    "        return np.array(sequences), np.array(labels, dtype=np.uint8)\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    cf         = config.Config()\n",
    "    rootPath   = pathlib.Path(cf.rootPath)\n",
    "    modelCheckpointPath = rootPath/'Callbacks'/'RNN'/f'{numClasses}'/'ModelCheckpoint'\n",
    "    \n",
    "    testSequences, testLabels = getSequences('Test')\n",
    "    testDataset = getDataset(testSequences, testLabels)\n",
    "    testDataset = testDataset.batch(BATCH_SIZE).prefetch(buffer_size = AUTOTUNE)\n",
    "    \n",
    "    savedModelPath = \"\" # you can insert the path to a saved model here\n",
    "    if savedModelPath == \"\":\n",
    "        savedModelPath = getBestSavedModel(modelCheckpointPath)\n",
    "    \n",
    "    savedModel = load_model(savedModelPath)\n",
    "    results = savedModel.evaluate(testDataset)\n",
    "    return results\n",
    "\n",
    "results = evaluateRNN()\n",
    "print(\"Loss: \", results[0], \"Accuracy: \", results[1])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

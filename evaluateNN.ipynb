{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "\n",
    "import pathlib\n",
    "import data\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE   = tf.data.experimental.AUTOTUNE\n",
    "dataObj    = data.Data()\n",
    "numClasses = dataObj.numClasses\n",
    "classNames = np.array(dataObj.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestSavedModel(modelCheckpointPath):\n",
    "    dirPaths  = sorted(modelCheckpointPath.glob(\"*\"))\n",
    "    minLoss   = float('inf')\n",
    "    bestModel = \"\"\n",
    "    for dirPath in dirPaths:\n",
    "        modelname = pathlib.Path(dirPath.name).stem\n",
    "        loss = float(modelname.split(\"_\")[-1])\n",
    "        if loss <= minLoss:\n",
    "            bestModel = dirPath\n",
    "            minLoss   = loss\n",
    "    return str(bestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateCNN():\n",
    "    def getDataSet(dataDirectory):\n",
    "        imagePathsDataset = tf.data.Dataset.list_files(str(dataDirectory/'*/*'))\n",
    "        return imagePathsDataset\n",
    "    \n",
    "    def getLabeledData(imagePath):\n",
    "        def getLabel(imagePath):\n",
    "            # convert the path to a list of path components\n",
    "            parts = tf.strings.split(imagePath, os.path.sep)\n",
    "            # The second to last is the class-directory\n",
    "            return parts[-2] == classNames\n",
    "    \n",
    "        def decodeImg(img):\n",
    "            # convert the compressed string to a 3D uint8 tensor\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "            # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "            img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "            # resize the image to the desired size.\n",
    "            return tf.image.resize(img, [299, 299])\n",
    "    \n",
    "        label = getLabel(imagePath)\n",
    "        # load the raw data from the file as a string\n",
    "        img = tf.io.read_file(imagePath)\n",
    "        img = decodeImg(img)\n",
    "        return img, label\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    rootPath            = pathlib.Path(r\"D:\\ActionRecognition\")\n",
    "    testDataDirectory   = rootPath/'Frames'/'Test'\n",
    "    modelCheckpointPath = rootPath/'Callbacks\\CNN'/f'{numClasses}'/'ModelCheckpoint'\n",
    "\n",
    "    testDataset = getDataSet(testDataDirectory)\n",
    "    testDataset = testDataset.map(getLabeledData, num_parallel_calls = AUTOTUNE)\n",
    "    testDataset = testDataset.batch(BATCH_SIZE).prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "    savedModelPath = \"\" # you can insert the path to a saved model here\n",
    "    if savedModelPath == \"\":\n",
    "        savedModelPath = getBestSavedModel(modelCheckpointPath)\n",
    "    \n",
    "    savedModel = load_model(savedModelPath)\n",
    "    results = savedModel.evaluate(testDataset)\n",
    "    return results\n",
    "\n",
    "results = evaluateCNN()\n",
    "print(\"Loss: \", results[0], \"Accuracy: \", results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRNN():\n",
    "    def getDataset(sequences, labels):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
    "        return dataset\n",
    "    \n",
    "    def getSequences(datasetType):\n",
    "        maxFrameCount = dataObj.getMaxFrameCount()\n",
    "        sequences = []\n",
    "        labels    = []\n",
    "        sequencesPath = pathlib.Path(r\"D:\\ActionRecognition\\Sequences\")\n",
    "        for dataRow in dataObj.data[:]:\n",
    "            if(datasetType == dataRow[0]):\n",
    "                sequencePath = sequencesPath/dataRow[0]/dataRow[1]/(dataRow[2] + \"_featureSequence.npy\")\n",
    "                sequence     = np.load(sequencePath)\n",
    "                sequence     = np.pad(sequence, ((0, maxFrameCount - int(dataRow[3])), (0, 0)), 'edge')\n",
    "                sequences.append(sequence)\n",
    "                label = dataObj.getClassIndex(dataRow[1])\n",
    "                labels.append(label)\n",
    "        return np.array(sequences), np.array(labels, dtype=np.uint8)\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    rootPath = pathlib.Path(r\"D:\\ActionRecognition\")\n",
    "    modelCheckpointPath = rootPath/'Callbacks\\RNN'/f'{numClasses}'/'ModelCheckpoint'\n",
    "    \n",
    "    testSequences, testLabels = getSequences('Test')\n",
    "    testDataset = getDataset(testSequences, testLabels)\n",
    "    testDataset = testDataset.batch(BATCH_SIZE).prefetch(buffer_size = AUTOTUNE)\n",
    "    \n",
    "    savedModelPath = \"\" # you can insert the path to a saved model here\n",
    "    if savedModelPath == \"\":\n",
    "        savedModelPath = getBestSavedModel(modelCheckpointPath)\n",
    "    \n",
    "    savedModel = load_model(savedModelPath)\n",
    "    results = savedModel.evaluate(testDataset)\n",
    "    return results\n",
    "\n",
    "results = evaluateRNN()\n",
    "print(\"Loss: \", results[0], \"Accuracy: \", results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

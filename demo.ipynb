{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "\n",
    "import directoryFunctions\n",
    "import extractFrames\n",
    "import pathlib\n",
    "import config\n",
    "import data\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing             import image\n",
    "from tensorflow.keras.models                    import load_model, Sequential\n",
    "\n",
    "\"\"\"\n",
    "Documentation:\n",
    "-cv2\n",
    "    1. get(), VideoCapture()\n",
    "        - https://docs.opencv.org/master/d8/dfe/classcv_1_1VideoCapture.html\n",
    "    2. imread()\n",
    "        - https://docs.opencv.org/master/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56\n",
    "    3. HersheyFonts, LineTypes, putText()\n",
    "        - https://docs.opencv.org/master/d6/d6e/group__imgproc__draw.html\n",
    "    2. VideoCapture properties\n",
    "        - https://docs.opencv.org/master/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d\n",
    "    3. VideoWriter(), write()\n",
    "        - https://docs.opencv.org/master/dd/d9e/classcv_1_1VideoWriter.html\n",
    "\n",
    "- numpy\n",
    "    1. expand_dims()\n",
    "        - https://numpy.org/doc/stable/reference/generated/numpy.expand_dims.html?highlight=expand_dims#numpy.expand_dims\n",
    "    2. load()\n",
    "        - https://numpy.org/doc/stable/reference/generated/numpy.load.html?highlight=load#numpy.load\n",
    "    3. save()\n",
    "        - https://numpy.org/doc/stable/reference/generated/numpy.save.html?highlight=save#numpy.save\n",
    "- pathlib\n",
    "    1. Path(), /, glob(), .stem\n",
    "        - https://docs.python.org/3/library/pathlib.html\n",
    "- tensorflow\n",
    "    - applications.inception_v3\n",
    "            1. preprocess_input()\n",
    "                - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/applications/inception_v3\n",
    "    - data.Dataset\n",
    "        1. predict()\n",
    "            - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/data/Dataset\n",
    "    - keras\n",
    "        - models\n",
    "            1. load_model()\n",
    "                - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/models/load_model\n",
    "            2. Sequential()\n",
    "                1. add(), compile(), fit()\n",
    "                    - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/Sequential\n",
    "        - preprocessing.image\n",
    "            1. img_to_array(), load_img()\n",
    "                - https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/preprocessing/image\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Name: getPartialModel\n",
    "Number of parameters: 1\n",
    "List of parameters:\n",
    "    1. savedModelPath | str | Path to the saved (CNN) model.\n",
    "Pre-condition:\n",
    "    1. savedModelPath exists and is a .h5 file.\n",
    "Post-condition:\n",
    "    1. Returns a model that contains some or all of the layers in the model saved in the\n",
    "       savedModelPath file. If a GlobalAveragePooling2D layer exists, then the returned model will \n",
    "       consist of all layers before and including that layer.\n",
    "\"\"\"\n",
    "def getPartialModel(savedModelPath):\n",
    "    loadedModel = load_model(savedModelPath)\n",
    "\n",
    "    indexOfGAPLayer = -1\n",
    "    # Get the index of the last GlobalAveragePooling2D layer starting from the back of the list of layers\n",
    "    for layer in loadedModel.layers[::-1]:\n",
    "        layer_type = str(type(layer))\n",
    "        if layer_type != \"<class 'tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D'>\":\n",
    "            indexOfGAPLayer -= 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if indexOfGAPLayer != -1:\n",
    "        indexAfterGAPLayer = indexOfGAPLayer + 1\n",
    "        partialModel = Sequential(loadedModel.layers[:indexAfterGAPLayer])\n",
    "    else:\n",
    "        # The GlobalAveragePooling2D Layer is the last layer. Thus, we get all the layers (no need to slice the list).\n",
    "        partialModel = Sequential(loadedModel.layers[:])\n",
    "\n",
    "    return partialModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Name: saveFeatures\n",
    "Number of parameters: 4\n",
    "List of parameters:\n",
    "    1. model           | tf.keras.models | Model that'll be used to extract the features.\n",
    "    2. framesPath      | pathlib.Path    | Path to the frames whose features are to be extracted.\n",
    "    3. videoFileName   | str             | Name of the video file that will be used to name the numpy file.\n",
    "    4. destinationPath | pathlib.Path    | Path used to save the numpy file containing the features.\n",
    "Pre-condition:\n",
    "    1. 'framesPath' exists and contains imgages.\n",
    "    2. 'destinationPath' exists.\n",
    "Post-condition:\n",
    "    1. Numpy files each containing an array of features of a frame and is saved at 'destinationPath'.\n",
    "    2. Nothing is returned.\n",
    "\"\"\"\n",
    "def saveFeatures(model, framesPath, videoFileName, destinationPath):\n",
    "    def extractFeatures(model, framePath):\n",
    "        frame = image.load_img(framePath, \n",
    "                               target_size   = (299,299), \n",
    "                               interpolation = \"lanczos\") # shape: (299, 299, 3): # of dim: 3\n",
    "        frame_arr = image.img_to_array(frame)             # pixel values in range [0,255]\n",
    "        frame_arr = preprocess_input(frame_arr)           # pixel values in range [-1, 1]\n",
    "        frame_arr = np.expand_dims(frame_arr, axis = 0)   # expands shape to: (1, 299, 299, 3): # of dim: 4\n",
    "        features  = model.predict(frame_arr)              # returns numpy array of shape: (1, 2048): # of dim: 2\n",
    "        features  = features[0]                           # shape: (2048, ): # of dim: 1\n",
    "        return features\n",
    "    \n",
    "    framesPaths = list(sorted(framesPath.glob(\"*.jpg\")))\n",
    "    numOfDigits = len(str(len(framesPaths)))\n",
    "    padding     = f'%0{numOfDigits}d'\n",
    "    for index, framePath in enumerate(framesPaths):\n",
    "        sequencePath = pathlib.Path(destinationPath/(videoFileName + \"_\" + str(padding % index)))\n",
    "        features = extractFeatures(model, framePath)\n",
    "        features = np.expand_dims(features, axis = 0)\n",
    "        print(f'Features from Frame # {index} saved at {sequencePath}')\n",
    "        np.save(sequencePath, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Name: predictCNN\n",
    "Number of parameters: 3\n",
    "List of parameters:\n",
    "    1. model      | tf.keras.models | Model that'll be used to make preditions.\n",
    "    2. framesPath | pathlib.Path    | Path to the frames that'll be used to make predictions.\n",
    "    3. classNames | list            | List of class names. \n",
    "Pre-condition:\n",
    "    1. 'framesPath' extists.\n",
    "Post-condition:\n",
    "    1. Return results after making predictions. The results is a dictionary, where the keys are indicies (int)\n",
    "       and the values are lists containing a label (str) and a percentage (float).\n",
    "\"\"\"\n",
    "def predictCNN(model, framesPath, classNames):\n",
    "    def getPredictions(model, framePath):\n",
    "        frame = image.load_img(framePath, \n",
    "                               target_size   = (299,299), \n",
    "                               interpolation = \"lanczos\")   # shape: (299, 299, 3): # of dim: 3\n",
    "        frame_arr   = image.img_to_array(frame)             # pixel values in range [0,255]\n",
    "        frame_arr   = preprocess_input(frame_arr)           # pixel values in range [-1, 1]\n",
    "        frame_arr   = np.expand_dims(frame_arr, axis = 0)   # expands shape to: (1, 299, 299, 3): # of dim: 4\n",
    "        predictions = model.predict(frame_arr)\n",
    "        predictions = predictions[0]\n",
    "        return predictions\n",
    "    \n",
    "    results = {}\n",
    "    framesPaths = list(sorted(framesPath.glob(\"*.jpg\")))\n",
    "    for index, framePath in enumerate(framesPaths):\n",
    "        predictions    = getPredictions(model, framePath)\n",
    "        topindex       = predictions.argsort()[-1:][0]\n",
    "        predictedLabel = classNames[topindex]\n",
    "        percentage     = predictions[topindex] * 100\n",
    "        results[index] = [predictedLabel, percentage]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Name: predictRNN\n",
    "Number of parameters: 3\n",
    "List of parameters:\n",
    "    1. model         | tf.keras.models | Model that'll be used to make preditions.\n",
    "    2. sequencesPath | pathlib.Path    | Path to the sequences that'll be used to make predictions.\n",
    "    3. classNames    | list            | List of class names. \n",
    "Pre-condition:\n",
    "    1. 'sequencesPath' extists.\n",
    "Post-condition:\n",
    "    1. Return results after making predictions. The results is a dictionary, where the keys are indicies (int)\n",
    "       and the values are lists containing a label (str) and a percentage (float).\n",
    "\"\"\"\n",
    "def predictRNN(model, sequencesPath, classNames):\n",
    "    def getPredictions(model, sequencePath):\n",
    "        sequence      = np.load(sequencePath)\n",
    "        sequence      = np.expand_dims(sequence, axis = 0)\n",
    "        predictions   = model.predict(sequence)\n",
    "        predictions   = predictions[0]\n",
    "        return predictions\n",
    "    \n",
    "    results = {}\n",
    "    sequencesPaths = list(sorted(sequencesPath.glob(\"*.npy\")))\n",
    "    for index, sequencePath in enumerate(sequencesPaths):\n",
    "        predictions    = getPredictions(model, sequencePath)\n",
    "        topindex       = predictions.argsort()[-1:][0]\n",
    "        predictedLabel = classNames[topindex]\n",
    "        percentage     = predictions[topindex] * 100\n",
    "        results[index] = [predictedLabel, percentage]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Name: createLabeledVideo\n",
    "Number of parameters: 5\n",
    "List of parameters:\n",
    "    1. videoFilePath  | str          | Path to the video that is to be labeled.\n",
    "    2. videoFileName  | str          | Name used to name the output video.\n",
    "    3. outputPath     | pathlib.Path | Path to save the output video.\n",
    "    4. cnnPredictions | dict         | Dictionary of labels (str) and predictions (int) generated from a CNN Model.\n",
    "    5. rnnPredictions | dict         | Dictionary of labels (str) and predictions (int) generated from a RNN Model.\n",
    "Pre-condition:\n",
    "    1. 'videoFilePath' exists and points to a video.\n",
    "    2. 'outputPath' exists.\n",
    "Post-condition:\n",
    "    1. A video is saved at 'outputPath' that is the labeled version of 'videoFileName'.\n",
    "    2. Nothing is returned.\n",
    "\"\"\"\n",
    "def createLabeledVideo(videoFilePath, videoFileName, outputPath, cnnPredictions, rnnPredictions):\n",
    "    outputFilePath = str(outputPath/f'{videoFileName}_labeled.avi')\n",
    "    vidCap = cv2.VideoCapture(videoFilePath) # Opens a video file for video capturing\n",
    "    width  = int(vidCap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(vidCap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = int(vidCap.get(cv2.CAP_PROP_FOURCC)) # *'XVID'  # fps    = int(vidCap.get(cv2.CAP_PROP_FPS))\n",
    "    fps    = 8\n",
    "    \n",
    "    videoWriter = cv2.VideoWriter(outputFilePath, fourcc, fps, (width, height))\n",
    "    tempDirectory = pathlib.Path(r\"./temp\")\n",
    "    framesPath = tempDirectory/'Frames'\n",
    "    frames = sorted(framesPath.glob(\"*\"))\n",
    "    for index, frame in enumerate(frames):\n",
    "        frame = cv2.imread(str(frame))\n",
    "        cv2.putText(frame, f'CNN: {cnnPredictions[index][0]} - {round(cnnPredictions[index][1], 2)}%', \n",
    "                    (1, 14), cv2.FONT_HERSHEY_DUPLEX , 0.45, (255, 100, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, f'RNN: {rnnPredictions[index][0]} - {round(rnnPredictions[index][1], 2)}%', \n",
    "                    (1, 30), cv2.FONT_HERSHEY_DUPLEX, 0.45, (255, 0, 100), 1, cv2.LINE_AA)\n",
    "        videoWriter.write(frame)\n",
    "    videoWriter.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Name: main\n",
    "Number of parameters: 0\n",
    "List of parameters: n/a\n",
    "Pre-condition: n/a\n",
    "Post-condition:\n",
    "    1. A labeled version of a video is saved. Where each frame of the video contains the predicted label and a percentage.\n",
    "    2. Nothing is returned.\n",
    "\"\"\"\n",
    "def main():\n",
    "    dataObj    = data.Data()\n",
    "    classNames = dataObj.classes\n",
    "    \n",
    "    tempDirectory = pathlib.Path(r\"./temp\")\n",
    "    directoryFunctions.removeDirectory(tempDirectory)\n",
    "    directoryFunctions.createDirectory(tempDirectory)\n",
    "    \n",
    "    cf            = config.Config()\n",
    "    rootPath      = pathlib.Path(cf.rootPath)\n",
    "    ucfVideosPath = pathlib.Path(cf.ucfVideosPath)\n",
    "    \n",
    "    # you can insert the path to a video here\n",
    "    videoFilePath = r\"D:\\ActionRecognition\\UCF-101\\Archery\\v_Archery_g01_c01.avi\"  \n",
    "    videoFileName = str(pathlib.Path(videoFilePath).stem)\n",
    "    \n",
    "    framesPath = tempDirectory/'Frames'\n",
    "    directoryFunctions.createDirectory(framesPath)\n",
    "    extractFrames.extractAllFrames(videoFilePath, videoFileName, str(framesPath))\n",
    "    \n",
    "    # you can insert the path to a saved model here\n",
    "    savedCNNModelPath = r\"D:\\ActionRecognition\\Callbacks\\CNN\\3\\ModelCheckpoint\\1589823036_CNN_001_0.89.h5\" \n",
    "    partialCNNModel   = getPartialModel(savedCNNModelPath)\n",
    "    \n",
    "    sequencesPath = tempDirectory/'Sequences'\n",
    "    directoryFunctions.createDirectory(sequencesPath)\n",
    "    saveFeatures(partialCNNModel, framesPath, videoFileName, sequencesPath)\n",
    "    \n",
    "    savedCNNModel  = load_model(savedCNNModelPath)\n",
    "    cnnPredictions = predictCNN(savedCNNModel, framesPath, classNames)\n",
    "    \n",
    "    # you can insert the path to a saved model here\n",
    "    savedRNNModelPath = r\"D:\\ActionRecognition\\Callbacks\\RNN\\3\\ModelCheckpoint\\1589823567_CNN_004_0.70.h5\" \n",
    "    savedRNNModel     = load_model(savedRNNModelPath)\n",
    "    rnnPredictions    = predictRNN(savedRNNModel, sequencesPath, classNames)\n",
    "    \n",
    "    createLabeledVideo(videoFilePath, videoFileName, tempDirectory, cnnPredictions, rnnPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
